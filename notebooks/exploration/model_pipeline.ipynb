{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Generate clusters on dataset as a feature\n",
    "2. Fit a variety of models using CV\n",
    "3. Test best CV model to evaluate final performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('../../data/processed/dtypes.json') as in_file:\n",
    "    non_date_dtypes = json.load(in_file)\n",
    "\n",
    "with open('../../data/processed/date_types.json') as in_file:\n",
    "    date_dtypes = json.load(in_file)\n",
    "\n",
    "date_cols = list(date_dtypes)\n",
    "\n",
    "# Read data, specifically parsing date columns as dates\n",
    "data = pd.read_csv('../../data/processed/data.csv', dtype=non_date_dtypes, parse_dates=date_cols)\n",
    "\n",
    "# data = data[data['DaysSinceLastRegistration'] <= 180]  # Must have donated within 180 days of each cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose target variable\n",
    "target_name = 'RegisteredInTargetPeriod'\n",
    "# target_name = 'RegisteredForPlateletsInTargetPeriod'\n",
    "\n",
    "# feature_names = ['DaysSinceLastRegistration', 'DaysSinceFirstRegistration', 'PastRegistrations', 'LastDonationLocation_Center',\n",
    "#                  'LastDonationType_WholeBlood', 'ModalDonationLocation_Center', 'DonationsPerDay', 'PercentOfTargetPeriodEligible']\n",
    "feature_names = ['DaysSinceLastRegistration', 'DaysSinceFirstRegistration', 'PastRegistrations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1    159303\n0    159303\nName: RegisteredInTargetPeriod, dtype: int64"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Downsample data\n",
    "\n",
    "# Separate majority (negative) and minority (positive) targets\n",
    "data_majority = data[data[target_name] == 0]\n",
    "data_minority = data[data[target_name] == 1]\n",
    "\n",
    "# Downsample the majority\n",
    "data_majority_downsampled = resample(data_majority, replace=False, n_samples=data[target_name].value_counts()[1], random_state=503)\n",
    "\n",
    "# Combine into a new dataset\n",
    "data_downsampled = pd.concat([data_majority_downsampled, data_minority])\n",
    "\n",
    "data_downsampled[target_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training feature set size: (254884, 3)\nTraining response set size: (254884,)\nTest feature set size: (63722, 3)\nTest response set size: (63722,)\n"
    }
   ],
   "source": [
    "X = data_downsampled.loc[:, feature_names]\n",
    "y = data_downsampled.loc[:, target_name]\n",
    "\n",
    "# Split data randomly\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=503)\n",
    "print(f\"Training feature set size: {X_train.shape}\")\n",
    "print(f\"Training response set size: {y_train.shape}\")\n",
    "print(f\"Test feature set size: {X_test.shape}\")\n",
    "print(f\"Test response set size: {y_test.shape}\")\n",
    "\n",
    "randstate = 503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n       n_clusters=5, n_init=10, n_jobs=None, precompute_distances='auto',\n       random_state=503, tol=0.0001, verbose=0)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=randstate)\n",
    "kmeans.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=5, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=None, oob_score=False, random_state=503,\n                       verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(max_depth=5, random_state=randstate)\n",
    "clf_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6800790935626628"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "y_pred = clf_rf.predict(X_test)\n",
    "clf_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(22445, 9436, 10950, 20891)\n              precision    recall  f1-score   support\n\n           0       0.67      0.70      0.69     31881\n           1       0.69      0.66      0.67     31841\n\n    accuracy                           0.68     63722\n   macro avg       0.68      0.68      0.68     63722\nweighted avg       0.68      0.68      0.68     63722\n\n"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print((tn, fp, fn, tp))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n                   n_estimators=50, random_state=503)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "clf_ab = AdaBoostClassifier(n_estimators=50, random_state=randstate)\n",
    "clf_ab.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6789962650262076"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "y_pred = clf_ab.predict(X_test)\n",
    "clf_ab.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}