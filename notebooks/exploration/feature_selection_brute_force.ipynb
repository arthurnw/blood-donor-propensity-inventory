{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain, combinations\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('../data/processed/dtypes.json') as in_file:\n",
    "    non_date_dtypes = json.load(in_file)\n",
    "\n",
    "with open('../data/processed/date_types.json') as in_file:\n",
    "    date_dtypes = json.load(in_file)\n",
    "\n",
    "date_cols = list(date_dtypes)\n",
    "print(non_date_dtypes)\n",
    "print(date_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data, specifically parsing date columns as dates\n",
    "data = pd.read_csv('../data/processed/data.csv', dtype=non_date_dtypes, parse_dates=date_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose target variable\n",
    "target_name = 'RegisteredInTargetPeriod'\n",
    "# target_name = 'RegisteredForPlateletsInTargetPeriod'\n",
    "\n",
    "# features = [col for col in list(data.columns) if col not in ('Random_ID', 'CutoffDate') and 'Target' not in col]\n",
    "features = ['DaysSinceLastRegistration', 'DaysSinceFirstRegistration',\n",
    "       'PastRegistrations', 'DaysSinceLastWholeBloodRegistration', 'PercentOfTargetPeriodEligible', 'LastDonationLocation_Center',\n",
    "       'LastDonationType_2UnitsRBC', 'LastDonationType_PlasmaApheresis',\n",
    "       'LastDonationType_PlateletApheresis',\n",
    "       'LastDonationType_PlateletsandConcurrentPlasma',\n",
    "       'LastDonationType_RBCwithPlasma', 'LastDonationType_RBCwithPlatelets',\n",
    "       'LastDonationType_RBCwithPlateletsandPlasma',\n",
    "       'LastDonationType_SingleUnitRecovery', 'PastWholeBloodRegistrations',\n",
    "       'PastCenterRegistrations', 'PastMobileRegistrations',\n",
    "       'ModalDonationLocation_Center']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_best_subset(estimator, X, y, max_size=5, cv=3):\n",
    "    \"\"\"Calculates the best model of up to max_size features of X.\n",
    "    estimator must have a fit and score functions.\n",
    "    X must be a DataFrame.\"\"\"\n",
    "\n",
    "    n_features = X.shape[1]\n",
    "    subsets = (combinations(range(n_features), k + 1) \n",
    "               for k in range(min(n_features, max_size)))\n",
    "\n",
    "    best_size_subset = []\n",
    "    k = 1\n",
    "    for subsets_k in subsets:  # for each list of subsets of the same size\n",
    "        print(f\"Trying subsets of size {k}...\")\n",
    "        best_score = -np.inf\n",
    "        best_subset = None\n",
    "        for subset in subsets_k: # for each subset\n",
    "            print(f\"\\tTrying feature subset: {list(subset)}...\")\n",
    "            estimator.fit(X.iloc[:, list(subset)], y)\n",
    "            # get the subset with the best score among subsets of the same size\n",
    "            score = estimator.score(X.iloc[:, list(subset)], y)\n",
    "            if score > best_score:\n",
    "                best_score, best_subset = score, subset\n",
    "        # to compare subsets of different sizes we must use CV\n",
    "        # first store the best subset of each size\n",
    "        best_size_subset.append(best_subset)\n",
    "        k += 1\n",
    "\n",
    "    # compare best subsets of each size\n",
    "    best_score = -np.inf\n",
    "    best_subset = None\n",
    "    list_scores = []\n",
    "    for subset in best_size_subset:\n",
    "        score = cross_val_score(estimator, X.iloc[:, list(subset)], y, cv=cv).mean()\n",
    "        list_scores.append(score)\n",
    "        if score > best_score:\n",
    "            best_score, best_subset = score, subset\n",
    "\n",
    "    return best_subset, best_score, best_size_subset, list_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority (negative) and minority (positive) targets\n",
    "data_majority = data[data[target_name] == 0]\n",
    "data_minority = data[data[target_name] == 1]\n",
    "\n",
    "# Downsample the majority\n",
    "data_majority_downsampled = resample(data_majority, replace=False, n_samples=data[target_name].value_counts()[1], random_state=503)\n",
    "\n",
    "# Combine into a new dataset\n",
    "data_downsampled = pd.concat([data_majority_downsampled, data_minority])\n",
    "\n",
    "# Set X and y\n",
    "X = data_downsampled.loc[:, features]\n",
    "y = data_downsampled.loc[:, target_name]\n",
    "\n",
    "# May also need to try downsampling before feeding into the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data randomly\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=503)\n",
    "print(f\"Training feature set size: {X_train.shape}\")\n",
    "print(f\"Training response set size: {y_train.shape}\")\n",
    "print(f\"Test feature set size: {X_test.shape}\")\n",
    "print(f\"Test response set size: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an estimator/classifier\n",
    "clf_logreg = LogisticRegression(penalty='none', random_state=503)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "best_subset, best_score, best_size_subset, list_scores = calculate_best_subset(clf_logreg, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(best_subset)  # 0, 2, 4, 5, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(best_size_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(list_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}