{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import joblib\n",
    "\n",
    "np.random.seed(503)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General parameters for the script\n",
    "target_name = 'RegisteredInTargetPeriod'  # Target variable\n",
    "features = [\n",
    "    'DaysSinceLastRegistration', 'DaysSinceFirstRegistration',\n",
    "    'PastRegistrations', 'LastDonationLocation_Center',\n",
    "    'LastDonationType_Platelets', 'CenterRegistrationProportion', 'DonationsPerDay',\n",
    "    'PlateletRegistrationProportion'\n",
    "]\n",
    "\n",
    "# Decide whether we're loading a subset or the full set\n",
    "# dataset_size = 'partial'\n",
    "dataset_size = 'full'\n",
    "\n",
    "if dataset_size == 'full':\n",
    "    file_names = {\n",
    "        'X': 'X_train_full.csv',\n",
    "        'y': 'y_train_full.csv',\n",
    "        'model': '../../models/classifier_full.pkl'\n",
    "    }\n",
    "elif dataset_size == 'partial':\n",
    "    file_names = {\n",
    "        'X': 'X_train.csv',\n",
    "        'y': 'y_train.csv',\n",
    "        'model': '../../models/classifier.pkl'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('../../data/processed/dtypes.json') as in_file:\n",
    "    non_date_dtypes = json.load(in_file)\n",
    "\n",
    "with open('../../data/processed/date_types.json') as in_file:\n",
    "    date_dtypes = json.load(in_file)\n",
    "\n",
    "date_cols = list(date_dtypes)\n",
    "\n",
    "# Read data, specifically parsing date columns as dates and only picking the features + target\n",
    "X_train = pd.read_csv('../../data/processed/{0}'.format(file_names['X']), dtype=non_date_dtypes, index_col=0)\n",
    "y_train = pd.read_csv('../../data/processed/{0}'.format(file_names['y']), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iter       Train Loss   Remaining Time \n         1           0.7534           23.30m\n         2           0.7273           22.93m\n         3           0.7177           22.89m\n         4           0.7133           22.76m\n         5           0.7108           23.01m\n         6           0.7096           22.78m\n         7           0.7086           22.44m\n         8           0.7078           22.18m\n         9           0.7071           21.96m\n        10           0.7067           21.78m\n        20           0.7039           19.79m\n        30           0.7031           18.11m\n        40           0.7028           16.33m\n        50           0.7024           14.36m\n        60           0.7022           12.43m\n        70           0.7021           10.56m\n        80           0.7020            8.71m\n        90           0.7018            6.87m\n       100           0.7017            5.06m\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GradientBoostingClassifier(learning_rate=0.5, n_estimators=128, verbose=1)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Fit model using parameters selected via cross-validation\n",
    "clf = GradientBoostingClassifier(n_estimators=128, learning_rate=0.5, verbose=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['../../models/classifier_full.pkl']"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Save model\n",
    "joblib.dump(clf, file_names['model'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594043978791",
   "display_name": "Python 3.7.7 64-bit ('oneblood-inventory': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}