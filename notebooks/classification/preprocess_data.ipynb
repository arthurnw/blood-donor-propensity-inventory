{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook processes the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import glob, os, json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "file_path = '../../data/raw'\n",
    "raw_files = glob.glob(file_path + '/*.csv')\n",
    "\n",
    "file_list = []\n",
    "\n",
    "for file in raw_files:\n",
    "    file_list.append(pd.read_csv(file, index_col=None, header=0))\n",
    "\n",
    "raw_data = pd.concat(file_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(3818852, 5)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Random_ID    RegistrationTime     OutCome DonationType DonationLocation\n0   52156190  6/27/2015 12:47:00    Donation  Whole Blood           Center\n1   52825057   2/26/2015 9:53:00    Donation  2 Units RBC           Mobile\n2   53025596   9/8/2015 16:49:59    Donation  Whole Blood           Mobile\n3    2056692  8/26/2015 12:15:00    Donation  Whole Blood           Mobile\n4   52879521  1/26/2015 17:18:00  Incomplete  Whole Blood           Center",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Random_ID</th>\n      <th>RegistrationTime</th>\n      <th>OutCome</th>\n      <th>DonationType</th>\n      <th>DonationLocation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>52156190</td>\n      <td>6/27/2015 12:47:00</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>Center</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>52825057</td>\n      <td>2/26/2015 9:53:00</td>\n      <td>Donation</td>\n      <td>2 Units RBC</td>\n      <td>Mobile</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>53025596</td>\n      <td>9/8/2015 16:49:59</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>Mobile</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2056692</td>\n      <td>8/26/2015 12:15:00</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>Mobile</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>52879521</td>\n      <td>1/26/2015 17:18:00</td>\n      <td>Incomplete</td>\n      <td>Whole Blood</td>\n      <td>Center</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "print(raw_data.shape)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide whether we're loading a subset or the full set\n",
    "# dataset_size = 'partial'\n",
    "dataset_size = 'full'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         Random_ID    RegistrationTime   OutCome        DonationType  \\\n9589      53639912  6/23/2015 14:20:59  Donation         Whole Blood   \n30664     52877130  4/13/2015 16:49:00  Donation         Whole Blood   \n55262     52869439  9/11/2015 13:38:00  Donation         Whole Blood   \n236526    53594657  6/23/2015 15:55:00  Donation         Whole Blood   \n240689    53165336   8/7/2015 17:19:59  Donation         Whole Blood   \n268039    53256162                  11       NaN                 NaN   \n284335    53373866     7/11/2016 17:42  Donation         Whole Blood   \n596076    52879414     9/20/2016 14:42  Donation         Whole Blood   \n670560    52971104    12/29/2016 13:49  Donation         Whole Blood   \n737587    53591355     3/23/2016 14:57  Donation         2 Units RBC   \n1660173    1160874  6/17/2017 10:08:00  Donation  Platelet Apheresis   \n1683446   54213719  7/15/2017 20:22:00  Donation         2 Units RBC   \n2076386   53929042  5/12/2017 16:59:00  Donation         Whole Blood   \n2175752   53742940   6/6/2017 13:41:00  Donation         Whole Blood   \n2223875   54766854  7/27/2017 17:49:00  Donation         Whole Blood   \n2787934   54826892   9/5/2018 13:27:00  Donation         Whole Blood   \n3213459   55696471  8/19/2019 11:27:59  Donation         Whole Blood   \n\n        DonationLocation  \n9589                 NaN  \n30664                NaN  \n55262                NaN  \n236526               NaN  \n240689               NaN  \n268039               NaN  \n284335               NaN  \n596076               NaN  \n670560               NaN  \n737587               NaN  \n1660173              NaN  \n1683446              NaN  \n2076386              NaN  \n2175752              NaN  \n2223875              NaN  \n2787934              NaN  \n3213459              NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Random_ID</th>\n      <th>RegistrationTime</th>\n      <th>OutCome</th>\n      <th>DonationType</th>\n      <th>DonationLocation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9589</th>\n      <td>53639912</td>\n      <td>6/23/2015 14:20:59</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>30664</th>\n      <td>52877130</td>\n      <td>4/13/2015 16:49:00</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>55262</th>\n      <td>52869439</td>\n      <td>9/11/2015 13:38:00</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>236526</th>\n      <td>53594657</td>\n      <td>6/23/2015 15:55:00</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>240689</th>\n      <td>53165336</td>\n      <td>8/7/2015 17:19:59</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>268039</th>\n      <td>53256162</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>284335</th>\n      <td>53373866</td>\n      <td>7/11/2016 17:42</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>596076</th>\n      <td>52879414</td>\n      <td>9/20/2016 14:42</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>670560</th>\n      <td>52971104</td>\n      <td>12/29/2016 13:49</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>737587</th>\n      <td>53591355</td>\n      <td>3/23/2016 14:57</td>\n      <td>Donation</td>\n      <td>2 Units RBC</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1660173</th>\n      <td>1160874</td>\n      <td>6/17/2017 10:08:00</td>\n      <td>Donation</td>\n      <td>Platelet Apheresis</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1683446</th>\n      <td>54213719</td>\n      <td>7/15/2017 20:22:00</td>\n      <td>Donation</td>\n      <td>2 Units RBC</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2076386</th>\n      <td>53929042</td>\n      <td>5/12/2017 16:59:00</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2175752</th>\n      <td>53742940</td>\n      <td>6/6/2017 13:41:00</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2223875</th>\n      <td>54766854</td>\n      <td>7/27/2017 17:49:00</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2787934</th>\n      <td>54826892</td>\n      <td>9/5/2018 13:27:00</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3213459</th>\n      <td>55696471</td>\n      <td>8/19/2019 11:27:59</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Show where we have NaNs/nulls\n",
    "raw_data[raw_data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with nulls\n",
    "cleaned_data = raw_data.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0   2015-06-27 12:47:00\n1   2015-02-26 09:53:00\n2   2015-09-08 16:49:59\n3   2015-08-26 12:15:00\n4   2015-01-26 17:18:00\nName: RegistrationTime, dtype: datetime64[ns]"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Clean up RegistrationTime: pad time with '00' seconds if only HH:MM is shown, then convert to a datetime type\n",
    "cleaned_data['RegistrationTime'] = cleaned_data['RegistrationTime'].apply(lambda c: c + ':00' if c.count(':') < 2 else c)\n",
    "cleaned_data['RegistrationTime'] = pd.to_datetime(cleaned_data['RegistrationTime'], format='%m/%d/%Y %H:%M:%S')\n",
    "cleaned_data['RegistrationTime'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Random_ID    RegistrationTime     OutCome DonationType DonationLocation\n0   52156190 2015-06-27 12:47:00    Donation  Whole Blood           Center\n1   52825057 2015-02-26 09:53:00    Donation  2 Units RBC           Mobile\n2   53025596 2015-09-08 16:49:59    Donation  Whole Blood           Mobile\n3    2056692 2015-08-26 12:15:00    Donation  Whole Blood           Mobile\n4   52879521 2015-01-26 17:18:00  Incomplete  Whole Blood           Center",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Random_ID</th>\n      <th>RegistrationTime</th>\n      <th>OutCome</th>\n      <th>DonationType</th>\n      <th>DonationLocation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>52156190</td>\n      <td>2015-06-27 12:47:00</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>Center</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>52825057</td>\n      <td>2015-02-26 09:53:00</td>\n      <td>Donation</td>\n      <td>2 Units RBC</td>\n      <td>Mobile</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>53025596</td>\n      <td>2015-09-08 16:49:59</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>Mobile</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2056692</td>\n      <td>2015-08-26 12:15:00</td>\n      <td>Donation</td>\n      <td>Whole Blood</td>\n      <td>Mobile</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>52879521</td>\n      <td>2015-01-26 17:18:00</td>\n      <td>Incomplete</td>\n      <td>Whole Blood</td>\n      <td>Center</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.to_csv('../../data/processed/cleaned_data.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Establish cutoff dates for data subsets\n",
    "2. Process the data so that we have, for each cutoff date, one record per donor consisting of:\n",
    "  * Recency: how long ago the donor donated\n",
    "  * Frequency: how many times the donor donated\n",
    "  * Time: how long the donor has been a donor\n",
    "  * Modal location: the location type (e.g. mobile vs. center) that the donor donated in most often\n",
    "  * Target: whether or not the donor donated in the target period\n",
    "  * Additional breakdowns of recency, frequency, location, and target by donation type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish cutoff dates for the \"chunks\" of our final dataset\n",
    "target_window_size = 90\n",
    "\n",
    "cutoff_dates = sorted([cutoff_date for cutoff_date\n",
    "    in [pd.to_datetime('2019-05-22 23:59:59', format='%Y-%m-%d %H:%M:%S') + pd.Timedelta(days=-target_window_size * i) for i in range(60)]\n",
    "    if cutoff_date.year >= 2015])\n",
    "\n",
    "if dataset_size == 'partial':\n",
    "    del cutoff_dates[4:]  # Remove all but the first four dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eligibility windows for different donation types\n",
    "eligibility_map = {\n",
    "    'Whole Blood': 56,\n",
    "    'Platelets and Concurrent Plasma': 28,\n",
    "    '2 Units RBC': 112,\n",
    "    'RBC with Platelets and Plasma': 56,\n",
    "    'Plasma Apheresis': 28,\n",
    "    'Platelet Apheresis': 7,\n",
    "    'RBC with Platelets': 56,\n",
    "    'Single Unit Recovery': 56,\n",
    "    'RBC with Plasma': 56\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Processed data file does not exist - proceeding.\n"
    }
   ],
   "source": [
    "if dataset_size == 'partial':\n",
    "    filename = 'data.csv'\n",
    "elif dataset_size == 'full':\n",
    "    filename = 'full_data.csv'\n",
    "\n",
    "# Remove old processed file\n",
    "try:\n",
    "    os.remove(f'../../data/processed/{filename}')\n",
    "except FileNotFoundError:\n",
    "    print(\"Processed data file does not exist - proceeding.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Generating data for cutoff date of 2015-03-14 23:59:59, target period of 2015-03-15 00:00:00 - 2015-06-12 23:59:59...\nGenerating data for cutoff date of 2015-06-12 23:59:59, target period of 2015-06-13 00:00:00 - 2015-09-10 23:59:59...\nGenerating data for cutoff date of 2015-09-10 23:59:59, target period of 2015-09-11 00:00:00 - 2015-12-09 23:59:59...\nGenerating data for cutoff date of 2015-12-09 23:59:59, target period of 2015-12-10 00:00:00 - 2016-03-08 23:59:59...\nGenerating data for cutoff date of 2016-03-08 23:59:59, target period of 2016-03-09 00:00:00 - 2016-06-06 23:59:59...\nGenerating data for cutoff date of 2016-06-06 23:59:59, target period of 2016-06-07 00:00:00 - 2016-09-04 23:59:59...\nGenerating data for cutoff date of 2016-09-04 23:59:59, target period of 2016-09-05 00:00:00 - 2016-12-03 23:59:59...\nGenerating data for cutoff date of 2016-12-03 23:59:59, target period of 2016-12-04 00:00:00 - 2017-03-03 23:59:59...\nGenerating data for cutoff date of 2017-03-03 23:59:59, target period of 2017-03-04 00:00:00 - 2017-06-01 23:59:59...\nGenerating data for cutoff date of 2017-06-01 23:59:59, target period of 2017-06-02 00:00:00 - 2017-08-30 23:59:59...\nGenerating data for cutoff date of 2017-08-30 23:59:59, target period of 2017-08-31 00:00:00 - 2017-11-28 23:59:59...\nGenerating data for cutoff date of 2017-11-28 23:59:59, target period of 2017-11-29 00:00:00 - 2018-02-26 23:59:59...\nGenerating data for cutoff date of 2018-02-26 23:59:59, target period of 2018-02-27 00:00:00 - 2018-05-27 23:59:59...\nGenerating data for cutoff date of 2018-05-27 23:59:59, target period of 2018-05-28 00:00:00 - 2018-08-25 23:59:59...\nGenerating data for cutoff date of 2018-08-25 23:59:59, target period of 2018-08-26 00:00:00 - 2018-11-23 23:59:59...\nGenerating data for cutoff date of 2018-11-23 23:59:59, target period of 2018-11-24 00:00:00 - 2019-02-21 23:59:59...\nGenerating data for cutoff date of 2019-02-21 23:59:59, target period of 2019-02-22 00:00:00 - 2019-05-22 23:59:59...\nGenerating data for cutoff date of 2019-05-22 23:59:59, target period of 2019-05-23 00:00:00 - 2019-08-20 23:59:59...\n"
    }
   ],
   "source": [
    "cutoff_subsets = []\n",
    "iteration = 0\n",
    "include_header = True\n",
    "\n",
    "for cutoff in cutoff_dates:\n",
    "    # cutoff = pd.to_datetime(cutoff_date, format='%Y-%m-%d %H:%M:%S')  # Convert to datetime object for easier time comparisons\n",
    "    target_start_date = cutoff + pd.Timedelta(seconds=1)  # Midnight of the day after cutoff\n",
    "    target_end_date = cutoff + pd.Timedelta(days=target_window_size)  # 11:59:59 PM of the nth day after cutoff\n",
    "    print(f\"Generating data for cutoff date of {cutoff}, target period of {target_start_date} - {target_end_date}...\")\n",
    "\n",
    "    # Filter data down to eligible registrations\n",
    "    cutoff_history = cleaned_data[cleaned_data['RegistrationTime'] <= cutoff]\n",
    "\n",
    "    # Calculate recency: difference between most recent donation date per donor, and the current cutoff date\n",
    "    # Calculate time: total days since first registration\n",
    "    recency = cutoff_history.groupby(by='Random_ID', as_index=False).agg({'RegistrationTime': ['min', 'max']})\n",
    "    recency.columns = recency.columns.droplevel(0)\n",
    "    recency.columns = ['Random_ID', 'FirstRegistrationTime', 'LastRegistrationTime']\n",
    "    recency['DaysSinceLastRegistration'] = (cutoff - recency['LastRegistrationTime']).dt.days  # Just capture the days portion\n",
    "    recency['DaysSinceFirstRegistration'] = (cutoff - recency['FirstRegistrationTime']).dt.days\n",
    "    recency.drop(['FirstRegistrationTime', 'LastRegistrationTime'], inplace=True, axis=1)  # Drop unneeded date/time columns\n",
    "    \n",
    "    # Calculate recency by DonationType\n",
    "    recency_type = cutoff_history.groupby(by=['Random_ID', 'DonationType'], as_index=False) \\\n",
    "                                 .agg({'RegistrationTime': 'max'}).rename(columns={'RegistrationTime': 'LastRegistrationTime'})\n",
    "    recency_type['DaysSinceLastRegistration'] = recency_type['LastRegistrationTime'].apply(lambda c: (cutoff - c).days)\n",
    "    recency_type = recency_type.pivot(index='Random_ID', columns='DonationType', values='DaysSinceLastRegistration') \\\n",
    "                               .reset_index().rename_axis(None, axis=1)  # Make Random_ID a column; remove index name\n",
    "    recency_type.columns= ['Random_ID'] + ['DaysSinceLast' + col_name.replace(' ', '') + 'Registration' for col_name in recency_type.columns if col_name != 'Random_ID']\n",
    "\n",
    "    # Calculate eligibility stats and last registration features\n",
    "    # Based on days since last donation, and type of last donation\n",
    "    last_reg = cutoff_history[cutoff_history['OutCome'] == \"Donation\"].sort_values('RegistrationTime', ascending=False).groupby(by='Random_ID').head(1)\n",
    "    last_reg['DaysSinceLastDonation'] = last_reg['RegistrationTime'].apply(lambda c: (cutoff - c).days)\n",
    "    last_reg['DaysEligible'] = last_reg.apply(lambda row: target_window_size - (eligibility_map[row['DonationType']] - row['DaysSinceLastDonation']), axis=1)\n",
    "    last_reg['PercentOfTargetPeriodEligible'] = last_reg['DaysEligible'].apply(lambda x: 1 if x > target_window_size else (0 if x < 0 else x / target_window_size))\n",
    "    last_reg['LastDonationLocation_Center'] = last_reg['DonationLocation'].apply(lambda x: 1 if x == \"Center\" else 0)\n",
    "    last_reg = last_reg.rename(columns={'DonationType': 'LastDonationType'})\n",
    "    last_reg['LastDonationType_Platelets'] = last_reg['LastDonationType'].apply(lambda x: 1 if x in ['RBC with Platelets', 'Platelet Apheresis',\n",
    "                                                                                                     'RBC with Platelets and Plasma', 'Platelets and Concurrent Plasma'] else 0)\n",
    "    # last_reg = pd.get_dummies(last_reg, columns=['LastDonationType'])\n",
    "    last_reg.columns = ['Random_ID'] + [col_name.replace(' ', '') for col_name in last_reg.columns if col_name != 'Random_ID']\n",
    "    # last_reg.drop(['RegistrationTime', 'OutCome', 'DonationLocation', 'DaysSinceLastDonation', 'LastDonationType_WholeBlood'], axis=1, inplace=True)\n",
    "    last_reg.drop(['RegistrationTime', 'OutCome', 'DonationLocation', 'DaysSinceLastDonation', 'LastDonationType'], axis=1, inplace=True)\n",
    "\n",
    "    # Calculate frequency: number of registrations for donation in the history period\n",
    "    frequency = cutoff_history.groupby(by='Random_ID', as_index=False).agg({'RegistrationTime': 'count'}).rename(columns={'RegistrationTime': 'PastRegistrations'})    \n",
    "\n",
    "    # Calculate frequency by DonationType\n",
    "    frequency_type = cutoff_history.groupby(by=['Random_ID', 'DonationType'], as_index=False) \\\n",
    "                                   .agg({'RegistrationTime': 'count'}).rename(columns={'RegistrationTime': 'TotalRegistrations'}) \\\n",
    "                                   .pivot(index='Random_ID', columns='DonationType', values='TotalRegistrations') \\\n",
    "                                   .reset_index().rename_axis(None, axis=1)  # Make Random_ID a column; remove index name\n",
    "    frequency_type.columns = ['Random_ID'] + ['Past' + col_name.replace(' ', '') + 'Registrations' for col_name in frequency_type.columns if col_name != 'Random_ID']\n",
    "\n",
    "    # Calculate frequency just for platelet products\n",
    "    frequency_platelets = cutoff_history[cutoff_history['DonationType'].isin(['RBC with Platelets', 'Platelet Apheresis',\n",
    "                                                                              'RBC with Platelets and Plasma', 'Platelets and Concurrent Plasma'])] \\\n",
    "                                                                       .groupby(by='Random_ID', as_index=False) \\\n",
    "                                                                       .agg({'RegistrationTime': 'count'}).rename(columns={'RegistrationTime': 'PastPlateletRegistrations'}) \n",
    "\n",
    "    # Filter data down to target period\n",
    "    cutoff_target = cleaned_data[(cleaned_data['RegistrationTime'] >= target_start_date) & (cleaned_data['RegistrationTime'] <= target_end_date)]\n",
    "\n",
    "    # Calculate base measure for target: how many total registrations each donor had in the target period\n",
    "    response = cutoff_target.groupby(by='Random_ID', as_index=False).agg({'RegistrationTime': 'count'}).rename(columns={'RegistrationTime': 'TargetRegistrations'})\n",
    "    \n",
    "    # Calculate sub-targets: how many registrations of each DonationType each donor had in the target period\n",
    "    response_type = cutoff_target.groupby(by=['Random_ID', 'DonationType'], as_index=False) \\\n",
    "                                 .agg({'RegistrationTime': 'count'}).rename(columns={'RegistrationTime': 'TotalRegistrations'}) \\\n",
    "                                 .pivot(index='Random_ID', columns='DonationType', values='TotalRegistrations') \\\n",
    "                                 .reset_index().rename_axis(None, axis=1)\n",
    "    response_type.columns = ['Random_ID'] + ['Target' + col_name.replace(' ', '') + 'Registrations' for col_name in response_type.columns if col_name != 'Random_ID']    \n",
    "\n",
    "    # Calculate target for platelet donations (combined):\n",
    "    response_platelets = cutoff_target[cutoff_target['DonationType'].isin(['RBC with Platelets', 'Platelet Apheresis',\n",
    "                                                                           'RBC with Platelets and Plasma', 'Platelets and Concurrent Plasma'])] \\\n",
    "                                                                    .groupby(by='Random_ID', as_index=False) \\\n",
    "                                                                    .agg({'RegistrationTime': 'count'}).rename(columns={'RegistrationTime': 'TargetPlateletRegistrations'})     \n",
    "\n",
    "    # Calculate registrations per location type\n",
    "    location_counts = cutoff_history.groupby(by=['Random_ID', 'DonationLocation'], as_index=False) \\\n",
    "                                    .agg({'RegistrationTime': 'count'}).rename(columns={'RegistrationTime': 'TotalRegistrations'})\n",
    "    \n",
    "    # Pivot to add as features\n",
    "    frequency_location = location_counts.pivot(index='Random_ID', columns='DonationLocation', values='TotalRegistrations').reset_index().rename_axis(None, axis=1)\n",
    "    frequency_location.columns = ['Random_ID'] + ['Past' + col_name.replace(' ', '') + 'Registrations' for col_name in frequency_location.columns if col_name != 'Random_ID']\n",
    "    frequency_location.fillna(0, inplace=True)\n",
    "    frequency_location['CenterRegistrationProportion'] = frequency_location['PastCenterRegistrations'] / (frequency_location['PastMobileRegistrations'] + frequency_location['PastCenterRegistrations'])\n",
    "    \n",
    "\n",
    "    # Calculate modal location per Random_ID\n",
    "    modal_location = location_counts.sort_values('TotalRegistrations', ascending=False).groupby(by='Random_ID').head(1).rename(columns={'DonationLocation': 'ModalDonationLocation'})\n",
    "    # Represent modal location as dummy variables - dropping the dummy for mobile locations to prevent multicollinearity\n",
    "    modal_dummies = pd.get_dummies(modal_location).drop(['TotalRegistrations', 'ModalDonationLocation_Mobile'], axis=1)\n",
    "\n",
    "    # Combine datasets to create a subset for the current cutoff date\n",
    "    # cutoff_subset = pd.merge(recency, frequency, how='left') \\\n",
    "    #                   .merge(recency_type, how='left') \\\n",
    "    #                   .merge(last_reg, how='left') \\\n",
    "    #                   .merge(frequency_type, how='left') \\\n",
    "    #                   .merge(frequency_location, how='left') \\\n",
    "    #                   .merge(frequency_platelets, how='left') \\\n",
    "    #                   .merge(modal_dummies, how='left') \\\n",
    "    #                   .merge(response, how='left') \\\n",
    "    #                   .merge(response_type, how='left') \\\n",
    "    #                   .merge(response_platelets, how='left')\n",
    "    cutoff_subset = pd.merge(recency, frequency, how='left') \\\n",
    "                      .merge(last_reg, how='left') \\\n",
    "                      .merge(frequency_location, how='left') \\\n",
    "                      .merge(frequency_platelets, how='left') \\\n",
    "                      .merge(modal_dummies, how='left') \\\n",
    "                      .merge(response, how='left')\n",
    "\n",
    "    # Add more features based on metadata or interactions    \n",
    "    nonzero_time_mask = (cutoff_subset['DaysSinceFirstRegistration'] != 0)\n",
    "    cutoff_subset['DonationsPerDay'] = 1\n",
    "    nonzero_time_subset = cutoff_subset[nonzero_time_mask]\n",
    "    cutoff_subset.loc[nonzero_time_mask, 'DonationsPerDay'] = nonzero_time_subset['PastRegistrations'] / nonzero_time_subset['DaysSinceFirstRegistration']\n",
    "    cutoff_subset['PlateletRegistrationProportion'] = cutoff_subset['PastPlateletRegistrations'] / cutoff_subset['PastRegistrations']\n",
    "    cutoff_subset['CutoffDate'] = cutoff\n",
    "    cutoff_subset['RegisteredInTargetPeriod'] = cutoff_subset['TargetRegistrations'].apply(lambda x: 0 if pd.isna(x) or x == 0 else 1)\n",
    "    # cutoff_subset['RegisteredForPlateletsInTargetPeriod'] = cutoff_subset['TargetPlateletRegistrations'].apply(lambda x: 0 if pd.isna(x) or x == 0 else 1)\n",
    "    # cutoff_subset['TargetPeriodEndDate'] = target_end_date  # Target period start date is implicitly midnight of the day after the cutoff date    \n",
    "\n",
    "    # Replace NaNs (the result of outer joins) with 0\n",
    "    cutoff_subset.fillna(0, inplace=True)\n",
    "\n",
    "    # Drop ineligible donors\n",
    "    cutoff_subset = cutoff_subset[cutoff_subset['PercentOfTargetPeriodEligible'] > 0]\n",
    "\n",
    "    # Add the current subset to the list to combine later\n",
    "    cutoff_subsets.append(cutoff_subset)\n",
    "\n",
    "    # Append to CSV\n",
    "    if iteration > 0:\n",
    "        include_header = False\n",
    "    \n",
    "    cutoff_subset.to_csv(f'../../data/processed/{filename}', index=False, header=include_header, mode='a')\n",
    "    iteration += 1\n",
    "\n",
    "# Combine all cutoff subsets together for processed data\n",
    "data = pd.concat(cutoff_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'Random_ID': 'int64', 'DaysSinceLastRegistration': 'int64', 'DaysSinceFirstRegistration': 'int64', 'PastRegistrations': 'int64', 'DaysEligible': 'float64', 'PercentOfTargetPeriodEligible': 'float64', 'LastDonationLocation_Center': 'float64', 'LastDonationType_Platelets': 'float64', 'PastCenterRegistrations': 'float64', 'PastMobileRegistrations': 'float64', 'CenterRegistrationProportion': 'float64', 'PastPlateletRegistrations': 'float64', 'ModalDonationLocation_Center': 'uint8', 'TargetRegistrations': 'float64', 'DonationsPerDay': 'float64', 'PlateletRegistrationProportion': 'float64', 'RegisteredInTargetPeriod': 'int64'}\n{'CutoffDate': 'datetime64[ns]'}\n"
    }
   ],
   "source": [
    "# Save data types as a dict for reading\n",
    "#dtypes_dict = data.dtypes.to_frame('dtypes').reset_index().set_index('index')['dtypes'].astype(str).to_dict()\n",
    "data_dtypes = data.dtypes.to_frame('dtypes').reset_index().set_index('index')['dtypes'].astype(str)\n",
    "non_date_dtypes = data_dtypes[data_dtypes != 'datetime64[ns]'].to_dict()\n",
    "date_dtypes = data_dtypes[data_dtypes == 'datetime64[ns]'].to_dict()\n",
    "\n",
    "with open('../../data/processed/dtypes.json', 'w') as out_file:\n",
    "    json.dump(non_date_dtypes, out_file)\n",
    "\n",
    "with open('../../data/processed/date_types.json', 'w') as out_file:\n",
    "    json.dump(date_dtypes, out_file)\n",
    "\n",
    "print(non_date_dtypes)\n",
    "print(date_dtypes)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}