{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General parameters for the script\n",
    "target_name = 'RegisteredInTargetPeriod'  # Target variable\n",
    "features = [\n",
    "    'DaysSinceLastRegistration', 'DaysSinceFirstRegistration',\n",
    "    'PastRegistrations', 'DaysEligible', 'LastDonationLocation_Center',\n",
    "    'LastDonationType_Platelets', 'ModalDonationLocation_Center',\n",
    "    'CenterRegistrationProportion', 'DonationsPerDay'\n",
    "]\n",
    "\n",
    "# Decide whether we're loading a subset or the full set\n",
    "dataset_size = 'partial'\n",
    "# dataset_size = 'full'\n",
    "\n",
    "if dataset_size == 'full':\n",
    "    file_name = 'full_data.csv'\n",
    "    file_suffix = '_full'\n",
    "elif dataset_size == 'partial':\n",
    "    file_name = 'data.csv'\n",
    "    file_suffix = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('../../data/processed/dtypes.json') as in_file:\n",
    "    non_date_dtypes = json.load(in_file)\n",
    "\n",
    "with open('../../data/processed/date_types.json') as in_file:\n",
    "    date_dtypes = json.load(in_file)\n",
    "\n",
    "date_cols = list(date_dtypes)\n",
    "\n",
    "# Read data, specifically parsing date columns as dates and only picking the features + target\n",
    "data = pd.read_csv(f'../../data/processed/{file_name}', dtype=non_date_dtypes, parse_dates=date_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['Random_ID', 'DaysSinceLastRegistration', 'DaysSinceFirstRegistration',\n       'PastRegistrations', 'DaysEligible', 'PercentOfTargetPeriodEligible',\n       'LastDonationLocation_Center', 'LastDonationType_Platelets',\n       'PastCenterRegistrations', 'PastMobileRegistrations',\n       'CenterRegistrationProportion', 'ModalDonationLocation_Center',\n       'TargetRegistrations', 'DonationsPerDay', 'CutoffDate',\n       'RegisteredInTargetPeriod'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take final cutoff date as a holdout set for demo purposes\n",
    "holdout_cutoff = data['CutoffDate'].unique()[-1]\n",
    "data[data['CutoffDate'] == holdout_cutoff][['Random_ID', target_name] + features].to_csv(f'../../data/processed/holdout{file_suffix}.csv')  # Only keep selected features + ID and save to CSV\n",
    "\n",
    "# Keep all other cutoff date sets for training/testing the model\n",
    "data = data[data['CutoffDate'] != holdout_cutoff][['Random_ID', target_name] + features]  # Only keep ID and selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    217646\n1    108823\nName: RegisteredInTargetPeriod, dtype: int64"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Separate majority (negative) and minority (positive) targets\n",
    "data_majority = data[data[target_name] == 0]\n",
    "data_minority = data[data[target_name] == 1]\n",
    "\n",
    "target_ratio = 2\n",
    "\n",
    "# Downsample the majority\n",
    "data_majority_downsampled = resample(data_majority, replace=False, n_samples=int(np.ceil(data[target_name].value_counts()[1]*target_ratio)), random_state=503)\n",
    "\n",
    "# Combine into a new dataset\n",
    "data_downsampled = pd.concat([data_majority_downsampled, data_minority])\n",
    "\n",
    "data_downsampled[target_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train, test = train_test_split(data_downsampled, test_size=0.2, random_state=503)\n",
    "\n",
    "# Write training and test datasets to CSV\n",
    "train.to_csv(f'../../data/processed/train{file_suffix}.csv')\n",
    "test.to_csv(f'../../data/processed/test{file_suffix}.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1593924481643",
   "display_name": "Python 3.7.7 64-bit ('oneblood-inventory': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}