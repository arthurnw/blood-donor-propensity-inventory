{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook processes the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import glob, os, json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "file_path = '../../data/raw'\n",
    "raw_files = glob.glob(file_path + '/*.csv')\n",
    "\n",
    "file_list = []\n",
    "\n",
    "for file in raw_files:\n",
    "    file_list.append(pd.read_csv(file, index_col=None, header=0))\n",
    "\n",
    "raw_data = pd.concat(file_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3818852, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random_ID</th>\n",
       "      <th>RegistrationTime</th>\n",
       "      <th>OutCome</th>\n",
       "      <th>DonationType</th>\n",
       "      <th>DonationLocation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52156190</td>\n",
       "      <td>6/27/2015 12:47:00</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52825057</td>\n",
       "      <td>2/26/2015 9:53:00</td>\n",
       "      <td>Donation</td>\n",
       "      <td>2 Units RBC</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53025596</td>\n",
       "      <td>9/8/2015 16:49:59</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2056692</td>\n",
       "      <td>8/26/2015 12:15:00</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52879521</td>\n",
       "      <td>1/26/2015 17:18:00</td>\n",
       "      <td>Incomplete</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Random_ID    RegistrationTime     OutCome DonationType DonationLocation\n",
       "0   52156190  6/27/2015 12:47:00    Donation  Whole Blood           Center\n",
       "1   52825057   2/26/2015 9:53:00    Donation  2 Units RBC           Mobile\n",
       "2   53025596   9/8/2015 16:49:59    Donation  Whole Blood           Mobile\n",
       "3    2056692  8/26/2015 12:15:00    Donation  Whole Blood           Mobile\n",
       "4   52879521  1/26/2015 17:18:00  Incomplete  Whole Blood           Center"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(raw_data.shape)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide whether we're loading a subset or the full set\n",
    "# dataset_size = 'partial'\n",
    "dataset_size = 'full'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random_ID</th>\n",
       "      <th>RegistrationTime</th>\n",
       "      <th>OutCome</th>\n",
       "      <th>DonationType</th>\n",
       "      <th>DonationLocation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9589</th>\n",
       "      <td>53639912</td>\n",
       "      <td>6/23/2015 14:20:59</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30664</th>\n",
       "      <td>52877130</td>\n",
       "      <td>4/13/2015 16:49:00</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55262</th>\n",
       "      <td>52869439</td>\n",
       "      <td>9/11/2015 13:38:00</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236526</th>\n",
       "      <td>53594657</td>\n",
       "      <td>6/23/2015 15:55:00</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240689</th>\n",
       "      <td>53165336</td>\n",
       "      <td>8/7/2015 17:19:59</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268039</th>\n",
       "      <td>53256162</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284335</th>\n",
       "      <td>53373866</td>\n",
       "      <td>7/11/2016 17:42</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596076</th>\n",
       "      <td>52879414</td>\n",
       "      <td>9/20/2016 14:42</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670560</th>\n",
       "      <td>52971104</td>\n",
       "      <td>12/29/2016 13:49</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737587</th>\n",
       "      <td>53591355</td>\n",
       "      <td>3/23/2016 14:57</td>\n",
       "      <td>Donation</td>\n",
       "      <td>2 Units RBC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660173</th>\n",
       "      <td>1160874</td>\n",
       "      <td>6/17/2017 10:08:00</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Platelet Apheresis</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683446</th>\n",
       "      <td>54213719</td>\n",
       "      <td>7/15/2017 20:22:00</td>\n",
       "      <td>Donation</td>\n",
       "      <td>2 Units RBC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076386</th>\n",
       "      <td>53929042</td>\n",
       "      <td>5/12/2017 16:59:00</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175752</th>\n",
       "      <td>53742940</td>\n",
       "      <td>6/6/2017 13:41:00</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223875</th>\n",
       "      <td>54766854</td>\n",
       "      <td>7/27/2017 17:49:00</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787934</th>\n",
       "      <td>54826892</td>\n",
       "      <td>9/5/2018 13:27:00</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213459</th>\n",
       "      <td>55696471</td>\n",
       "      <td>8/19/2019 11:27:59</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Random_ID    RegistrationTime   OutCome        DonationType  \\\n",
       "9589      53639912  6/23/2015 14:20:59  Donation         Whole Blood   \n",
       "30664     52877130  4/13/2015 16:49:00  Donation         Whole Blood   \n",
       "55262     52869439  9/11/2015 13:38:00  Donation         Whole Blood   \n",
       "236526    53594657  6/23/2015 15:55:00  Donation         Whole Blood   \n",
       "240689    53165336   8/7/2015 17:19:59  Donation         Whole Blood   \n",
       "268039    53256162                  11       NaN                 NaN   \n",
       "284335    53373866     7/11/2016 17:42  Donation         Whole Blood   \n",
       "596076    52879414     9/20/2016 14:42  Donation         Whole Blood   \n",
       "670560    52971104    12/29/2016 13:49  Donation         Whole Blood   \n",
       "737587    53591355     3/23/2016 14:57  Donation         2 Units RBC   \n",
       "1660173    1160874  6/17/2017 10:08:00  Donation  Platelet Apheresis   \n",
       "1683446   54213719  7/15/2017 20:22:00  Donation         2 Units RBC   \n",
       "2076386   53929042  5/12/2017 16:59:00  Donation         Whole Blood   \n",
       "2175752   53742940   6/6/2017 13:41:00  Donation         Whole Blood   \n",
       "2223875   54766854  7/27/2017 17:49:00  Donation         Whole Blood   \n",
       "2787934   54826892   9/5/2018 13:27:00  Donation         Whole Blood   \n",
       "3213459   55696471  8/19/2019 11:27:59  Donation         Whole Blood   \n",
       "\n",
       "        DonationLocation  \n",
       "9589                 NaN  \n",
       "30664                NaN  \n",
       "55262                NaN  \n",
       "236526               NaN  \n",
       "240689               NaN  \n",
       "268039               NaN  \n",
       "284335               NaN  \n",
       "596076               NaN  \n",
       "670560               NaN  \n",
       "737587               NaN  \n",
       "1660173              NaN  \n",
       "1683446              NaN  \n",
       "2076386              NaN  \n",
       "2175752              NaN  \n",
       "2223875              NaN  \n",
       "2787934              NaN  \n",
       "3213459              NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show where we have NaNs/nulls\n",
    "raw_data[raw_data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with nulls\n",
    "cleaned_data = raw_data.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rthrw\\miniconda3\\envs\\oneblood-inventory\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\rthrw\\miniconda3\\envs\\oneblood-inventory\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   2015-06-27 12:47:00\n",
       "1   2015-02-26 09:53:00\n",
       "2   2015-09-08 16:49:59\n",
       "3   2015-08-26 12:15:00\n",
       "4   2015-01-26 17:18:00\n",
       "Name: RegistrationTime, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up RegistrationTime: pad time with '00' seconds if only HH:MM is shown, then convert to a datetime type\n",
    "cleaned_data['RegistrationTime'] = cleaned_data['RegistrationTime'].apply(lambda c: c + ':00' if c.count(':') < 2 else c)\n",
    "cleaned_data['RegistrationTime'] = pd.to_datetime(cleaned_data['RegistrationTime'], format='%m/%d/%Y %H:%M:%S')\n",
    "cleaned_data['RegistrationTime'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random_ID</th>\n",
       "      <th>RegistrationTime</th>\n",
       "      <th>OutCome</th>\n",
       "      <th>DonationType</th>\n",
       "      <th>DonationLocation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52156190</td>\n",
       "      <td>2015-06-27 12:47:00</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52825057</td>\n",
       "      <td>2015-02-26 09:53:00</td>\n",
       "      <td>Donation</td>\n",
       "      <td>2 Units RBC</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53025596</td>\n",
       "      <td>2015-09-08 16:49:59</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2056692</td>\n",
       "      <td>2015-08-26 12:15:00</td>\n",
       "      <td>Donation</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52879521</td>\n",
       "      <td>2015-01-26 17:18:00</td>\n",
       "      <td>Incomplete</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Random_ID    RegistrationTime     OutCome DonationType DonationLocation\n",
       "0   52156190 2015-06-27 12:47:00    Donation  Whole Blood           Center\n",
       "1   52825057 2015-02-26 09:53:00    Donation  2 Units RBC           Mobile\n",
       "2   53025596 2015-09-08 16:49:59    Donation  Whole Blood           Mobile\n",
       "3    2056692 2015-08-26 12:15:00    Donation  Whole Blood           Mobile\n",
       "4   52879521 2015-01-26 17:18:00  Incomplete  Whole Blood           Center"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.to_csv('../../data/processed/cleaned_data.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Establish cutoff dates for data subsets\n",
    "2. Process the data so that we have, for each cutoff date, one record per donor consisting of:\n",
    "  * Recency: how long ago the donor donated\n",
    "  * Frequency: how many times the donor donated\n",
    "  * Time: how long the donor has been a donor\n",
    "  * Modal location: the location type (e.g. mobile vs. center) that the donor donated in most often\n",
    "  * Target: whether or not the donor donated in the target period\n",
    "  * Additional breakdowns of recency, frequency, location, and target by donation type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2015-01-13 23:59:59'),\n",
       " Timestamp('2015-02-12 23:59:59'),\n",
       " Timestamp('2015-03-14 23:59:59'),\n",
       " Timestamp('2015-04-13 23:59:59'),\n",
       " Timestamp('2015-05-13 23:59:59'),\n",
       " Timestamp('2015-06-12 23:59:59'),\n",
       " Timestamp('2015-07-12 23:59:59'),\n",
       " Timestamp('2015-08-11 23:59:59'),\n",
       " Timestamp('2015-09-10 23:59:59'),\n",
       " Timestamp('2015-10-10 23:59:59'),\n",
       " Timestamp('2015-11-09 23:59:59'),\n",
       " Timestamp('2015-12-09 23:59:59'),\n",
       " Timestamp('2016-01-08 23:59:59'),\n",
       " Timestamp('2016-02-07 23:59:59'),\n",
       " Timestamp('2016-03-08 23:59:59'),\n",
       " Timestamp('2016-04-07 23:59:59'),\n",
       " Timestamp('2016-05-07 23:59:59'),\n",
       " Timestamp('2016-06-06 23:59:59'),\n",
       " Timestamp('2016-07-06 23:59:59'),\n",
       " Timestamp('2016-08-05 23:59:59'),\n",
       " Timestamp('2016-09-04 23:59:59'),\n",
       " Timestamp('2016-10-04 23:59:59'),\n",
       " Timestamp('2016-11-03 23:59:59'),\n",
       " Timestamp('2016-12-03 23:59:59'),\n",
       " Timestamp('2017-01-02 23:59:59'),\n",
       " Timestamp('2017-02-01 23:59:59'),\n",
       " Timestamp('2017-03-03 23:59:59'),\n",
       " Timestamp('2017-04-02 23:59:59'),\n",
       " Timestamp('2017-05-02 23:59:59'),\n",
       " Timestamp('2017-06-01 23:59:59'),\n",
       " Timestamp('2017-07-01 23:59:59'),\n",
       " Timestamp('2017-07-31 23:59:59'),\n",
       " Timestamp('2017-08-30 23:59:59'),\n",
       " Timestamp('2017-09-29 23:59:59'),\n",
       " Timestamp('2017-10-29 23:59:59'),\n",
       " Timestamp('2017-11-28 23:59:59'),\n",
       " Timestamp('2017-12-28 23:59:59'),\n",
       " Timestamp('2018-01-27 23:59:59'),\n",
       " Timestamp('2018-02-26 23:59:59'),\n",
       " Timestamp('2018-03-28 23:59:59'),\n",
       " Timestamp('2018-04-27 23:59:59'),\n",
       " Timestamp('2018-05-27 23:59:59'),\n",
       " Timestamp('2018-06-26 23:59:59'),\n",
       " Timestamp('2018-07-26 23:59:59'),\n",
       " Timestamp('2018-08-25 23:59:59'),\n",
       " Timestamp('2018-09-24 23:59:59'),\n",
       " Timestamp('2018-10-24 23:59:59'),\n",
       " Timestamp('2018-11-23 23:59:59'),\n",
       " Timestamp('2018-12-23 23:59:59'),\n",
       " Timestamp('2019-01-22 23:59:59'),\n",
       " Timestamp('2019-02-21 23:59:59'),\n",
       " Timestamp('2019-03-23 23:59:59'),\n",
       " Timestamp('2019-04-22 23:59:59'),\n",
       " Timestamp('2019-05-22 23:59:59'),\n",
       " Timestamp('2019-06-21 23:59:59'),\n",
       " Timestamp('2019-07-21 23:59:59')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish cutoff dates for the \"chunks\" of our final dataset\n",
    "target_window_size = 30\n",
    "final_cutoff = pd.to_datetime('2019-08-20 23:59:59') + pd.Timedelta(days=-target_window_size)  # 8/20/2019 is the final resgistration in the dataset\n",
    "\n",
    "cutoff_dates = sorted([cutoff_date for cutoff_date\n",
    "    in [pd.to_datetime(final_cutoff, format='%Y-%m-%d %H:%M:%S') + pd.Timedelta(days=-target_window_size * i) for i in range(60)]\n",
    "    if cutoff_date.year >= 2015])\n",
    "\n",
    "if dataset_size == 'partial':\n",
    "    del cutoff_dates[:-4]  # Remove all but the first four dates\n",
    "    \n",
    "cutoff_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eligibility windows for different donation types\n",
    "eligibility_map = {\n",
    "    'Whole Blood': 56,\n",
    "    'Platelets and Concurrent Plasma': 28,\n",
    "    '2 Units RBC': 112,\n",
    "    'RBC with Platelets and Plasma': 56,\n",
    "    'Plasma Apheresis': 28,\n",
    "    'Platelet Apheresis': 7,\n",
    "    'RBC with Platelets': 56,\n",
    "    'Single Unit Recovery': 56,\n",
    "    'RBC with Plasma': 56\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dataset_size == 'partial':\n",
    "    filename = 'data.csv'\n",
    "elif dataset_size == 'full':\n",
    "    filename = 'full_data.csv'\n",
    "\n",
    "# Remove old processed file\n",
    "try:\n",
    "    os.remove(f'../../data/processed/{filename}')\n",
    "except FileNotFoundError:\n",
    "    print(\"Processed data file does not exist - proceeding.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data for cutoff date of 2015-01-13 23:59:59, target period of 2015-01-14 00:00:00 - 2015-02-12 23:59:59...\n",
      "Generating data for cutoff date of 2015-02-12 23:59:59, target period of 2015-02-13 00:00:00 - 2015-03-14 23:59:59...\n",
      "Generating data for cutoff date of 2015-03-14 23:59:59, target period of 2015-03-15 00:00:00 - 2015-04-13 23:59:59...\n",
      "Generating data for cutoff date of 2015-04-13 23:59:59, target period of 2015-04-14 00:00:00 - 2015-05-13 23:59:59...\n",
      "Generating data for cutoff date of 2015-05-13 23:59:59, target period of 2015-05-14 00:00:00 - 2015-06-12 23:59:59...\n",
      "Generating data for cutoff date of 2015-06-12 23:59:59, target period of 2015-06-13 00:00:00 - 2015-07-12 23:59:59...\n",
      "Generating data for cutoff date of 2015-07-12 23:59:59, target period of 2015-07-13 00:00:00 - 2015-08-11 23:59:59...\n",
      "Generating data for cutoff date of 2015-08-11 23:59:59, target period of 2015-08-12 00:00:00 - 2015-09-10 23:59:59...\n",
      "Generating data for cutoff date of 2015-09-10 23:59:59, target period of 2015-09-11 00:00:00 - 2015-10-10 23:59:59...\n",
      "Generating data for cutoff date of 2015-10-10 23:59:59, target period of 2015-10-11 00:00:00 - 2015-11-09 23:59:59...\n",
      "Generating data for cutoff date of 2015-11-09 23:59:59, target period of 2015-11-10 00:00:00 - 2015-12-09 23:59:59...\n",
      "Generating data for cutoff date of 2015-12-09 23:59:59, target period of 2015-12-10 00:00:00 - 2016-01-08 23:59:59...\n",
      "Generating data for cutoff date of 2016-01-08 23:59:59, target period of 2016-01-09 00:00:00 - 2016-02-07 23:59:59...\n",
      "Generating data for cutoff date of 2016-02-07 23:59:59, target period of 2016-02-08 00:00:00 - 2016-03-08 23:59:59...\n",
      "Generating data for cutoff date of 2016-03-08 23:59:59, target period of 2016-03-09 00:00:00 - 2016-04-07 23:59:59...\n",
      "Generating data for cutoff date of 2016-04-07 23:59:59, target period of 2016-04-08 00:00:00 - 2016-05-07 23:59:59...\n",
      "Generating data for cutoff date of 2016-05-07 23:59:59, target period of 2016-05-08 00:00:00 - 2016-06-06 23:59:59...\n",
      "Generating data for cutoff date of 2016-06-06 23:59:59, target period of 2016-06-07 00:00:00 - 2016-07-06 23:59:59...\n",
      "Generating data for cutoff date of 2016-07-06 23:59:59, target period of 2016-07-07 00:00:00 - 2016-08-05 23:59:59...\n",
      "Generating data for cutoff date of 2016-08-05 23:59:59, target period of 2016-08-06 00:00:00 - 2016-09-04 23:59:59...\n",
      "Generating data for cutoff date of 2016-09-04 23:59:59, target period of 2016-09-05 00:00:00 - 2016-10-04 23:59:59...\n",
      "Generating data for cutoff date of 2016-10-04 23:59:59, target period of 2016-10-05 00:00:00 - 2016-11-03 23:59:59...\n",
      "Generating data for cutoff date of 2016-11-03 23:59:59, target period of 2016-11-04 00:00:00 - 2016-12-03 23:59:59...\n",
      "Generating data for cutoff date of 2016-12-03 23:59:59, target period of 2016-12-04 00:00:00 - 2017-01-02 23:59:59...\n",
      "Generating data for cutoff date of 2017-01-02 23:59:59, target period of 2017-01-03 00:00:00 - 2017-02-01 23:59:59...\n",
      "Generating data for cutoff date of 2017-02-01 23:59:59, target period of 2017-02-02 00:00:00 - 2017-03-03 23:59:59...\n",
      "Generating data for cutoff date of 2017-03-03 23:59:59, target period of 2017-03-04 00:00:00 - 2017-04-02 23:59:59...\n",
      "Generating data for cutoff date of 2017-04-02 23:59:59, target period of 2017-04-03 00:00:00 - 2017-05-02 23:59:59...\n",
      "Generating data for cutoff date of 2017-05-02 23:59:59, target period of 2017-05-03 00:00:00 - 2017-06-01 23:59:59...\n",
      "Generating data for cutoff date of 2017-06-01 23:59:59, target period of 2017-06-02 00:00:00 - 2017-07-01 23:59:59...\n",
      "Generating data for cutoff date of 2017-07-01 23:59:59, target period of 2017-07-02 00:00:00 - 2017-07-31 23:59:59...\n",
      "Generating data for cutoff date of 2017-07-31 23:59:59, target period of 2017-08-01 00:00:00 - 2017-08-30 23:59:59...\n",
      "Generating data for cutoff date of 2017-08-30 23:59:59, target period of 2017-08-31 00:00:00 - 2017-09-29 23:59:59...\n",
      "Generating data for cutoff date of 2017-09-29 23:59:59, target period of 2017-09-30 00:00:00 - 2017-10-29 23:59:59...\n",
      "Generating data for cutoff date of 2017-10-29 23:59:59, target period of 2017-10-30 00:00:00 - 2017-11-28 23:59:59...\n",
      "Generating data for cutoff date of 2017-11-28 23:59:59, target period of 2017-11-29 00:00:00 - 2017-12-28 23:59:59...\n",
      "Generating data for cutoff date of 2017-12-28 23:59:59, target period of 2017-12-29 00:00:00 - 2018-01-27 23:59:59...\n",
      "Generating data for cutoff date of 2018-01-27 23:59:59, target period of 2018-01-28 00:00:00 - 2018-02-26 23:59:59...\n",
      "Generating data for cutoff date of 2018-02-26 23:59:59, target period of 2018-02-27 00:00:00 - 2018-03-28 23:59:59...\n",
      "Generating data for cutoff date of 2018-03-28 23:59:59, target period of 2018-03-29 00:00:00 - 2018-04-27 23:59:59...\n",
      "Generating data for cutoff date of 2018-04-27 23:59:59, target period of 2018-04-28 00:00:00 - 2018-05-27 23:59:59...\n",
      "Generating data for cutoff date of 2018-05-27 23:59:59, target period of 2018-05-28 00:00:00 - 2018-06-26 23:59:59...\n",
      "Generating data for cutoff date of 2018-06-26 23:59:59, target period of 2018-06-27 00:00:00 - 2018-07-26 23:59:59...\n",
      "Generating data for cutoff date of 2018-07-26 23:59:59, target period of 2018-07-27 00:00:00 - 2018-08-25 23:59:59...\n",
      "Generating data for cutoff date of 2018-08-25 23:59:59, target period of 2018-08-26 00:00:00 - 2018-09-24 23:59:59...\n",
      "Generating data for cutoff date of 2018-09-24 23:59:59, target period of 2018-09-25 00:00:00 - 2018-10-24 23:59:59...\n",
      "Generating data for cutoff date of 2018-10-24 23:59:59, target period of 2018-10-25 00:00:00 - 2018-11-23 23:59:59...\n",
      "Generating data for cutoff date of 2018-11-23 23:59:59, target period of 2018-11-24 00:00:00 - 2018-12-23 23:59:59...\n",
      "Generating data for cutoff date of 2018-12-23 23:59:59, target period of 2018-12-24 00:00:00 - 2019-01-22 23:59:59...\n",
      "Generating data for cutoff date of 2019-01-22 23:59:59, target period of 2019-01-23 00:00:00 - 2019-02-21 23:59:59...\n",
      "Generating data for cutoff date of 2019-02-21 23:59:59, target period of 2019-02-22 00:00:00 - 2019-03-23 23:59:59...\n",
      "Generating data for cutoff date of 2019-03-23 23:59:59, target period of 2019-03-24 00:00:00 - 2019-04-22 23:59:59...\n",
      "Generating data for cutoff date of 2019-04-22 23:59:59, target period of 2019-04-23 00:00:00 - 2019-05-22 23:59:59...\n",
      "Generating data for cutoff date of 2019-05-22 23:59:59, target period of 2019-05-23 00:00:00 - 2019-06-21 23:59:59...\n",
      "Generating data for cutoff date of 2019-06-21 23:59:59, target period of 2019-06-22 00:00:00 - 2019-07-21 23:59:59...\n",
      "Generating data for cutoff date of 2019-07-21 23:59:59, target period of 2019-07-22 00:00:00 - 2019-08-20 23:59:59...\n"
     ]
    }
   ],
   "source": [
    "cutoff_subsets = []\n",
    "iteration = 0\n",
    "include_header = True\n",
    "\n",
    "for cutoff in cutoff_dates:\n",
    "    # cutoff = pd.to_datetime(cutoff_date, format='%Y-%m-%d %H:%M:%S')  # Convert to datetime object for easier time comparisons\n",
    "    target_start_date = cutoff + pd.Timedelta(seconds=1)  # Midnight of the day after cutoff\n",
    "    target_end_date = cutoff + pd.Timedelta(days=target_window_size)  # 11:59:59 PM of the nth day after cutoff\n",
    "    print(f\"Generating data for cutoff date of {cutoff}, target period of {target_start_date} - {target_end_date}...\")\n",
    "\n",
    "    # Filter data down to eligible registrations\n",
    "    cutoff_history = cleaned_data[cleaned_data['RegistrationTime'] <= cutoff]\n",
    "\n",
    "    # Calculate recency: difference between most recent donation date per donor, and the current cutoff date\n",
    "    # Calculate time: total days since first registration\n",
    "    recency = cutoff_history.groupby(by='Random_ID', as_index=False).agg({'RegistrationTime': ['min', 'max']})\n",
    "    recency.columns = recency.columns.droplevel(0)\n",
    "    recency.columns = ['Random_ID', 'FirstRegistrationTime', 'LastRegistrationTime']\n",
    "    recency['DaysSinceLastRegistration'] = (cutoff - recency['LastRegistrationTime']).dt.days  # Just capture the days portion\n",
    "    recency['DaysSinceFirstRegistration'] = (cutoff - recency['FirstRegistrationTime']).dt.days\n",
    "    recency.drop(['FirstRegistrationTime', 'LastRegistrationTime'], inplace=True, axis=1)  # Drop unneeded date/time columns\n",
    "    \n",
    "    # Calculate recency by DonationType\n",
    "    recency_type = cutoff_history.groupby(by=['Random_ID', 'DonationType'], as_index=False) \\\n",
    "                                 .agg({'RegistrationTime': 'max'}).rename(columns={'RegistrationTime': 'LastRegistrationTime'})\n",
    "    recency_type['DaysSinceLastRegistration'] = recency_type['LastRegistrationTime'].apply(lambda c: (cutoff - c).days)\n",
    "    recency_type = recency_type.pivot(index='Random_ID', columns='DonationType', values='DaysSinceLastRegistration') \\\n",
    "                               .reset_index().rename_axis(None, axis=1)  # Make Random_ID a column; remove index name\n",
    "    recency_type.columns= ['Random_ID'] + ['DaysSinceLast' + col_name.replace(' ', '') + 'Registration' for col_name in recency_type.columns if col_name != 'Random_ID']\n",
    "\n",
    "    # Calculate eligibility stats and last registration features\n",
    "    # Based on days since last donation, and type of last donation\n",
    "    last_reg = cutoff_history[cutoff_history['OutCome'] == \"Donation\"].sort_values('RegistrationTime', ascending=False).groupby(by='Random_ID').head(1)\n",
    "    last_reg['DaysSinceLastDonation'] = last_reg['RegistrationTime'].apply(lambda c: (cutoff - c).days)\n",
    "    last_reg['DaysEligible'] = last_reg.apply(lambda row: target_window_size - (eligibility_map[row['DonationType']] - row['DaysSinceLastDonation']), axis=1)\n",
    "    last_reg['PercentOfTargetPeriodEligible'] = last_reg['DaysEligible'].apply(lambda x: 1 if x > target_window_size else (0 if x < 0 else x / target_window_size))\n",
    "    last_reg['LastDonationLocation_Center'] = last_reg['DonationLocation'].apply(lambda x: 1 if x == \"Center\" else 0)\n",
    "    last_reg = last_reg.rename(columns={'DonationType': 'LastDonationType'})\n",
    "    last_reg['LastDonationType_Platelets'] = last_reg['LastDonationType'].apply(lambda x: 1 if x in ['RBC with Platelets', 'Platelet Apheresis',\n",
    "                                                                                                     'RBC with Platelets and Plasma', 'Platelets and Concurrent Plasma'] else 0)\n",
    "    # last_reg = pd.get_dummies(last_reg, columns=['LastDonationType'])\n",
    "    last_reg.columns = ['Random_ID'] + [col_name.replace(' ', '') for col_name in last_reg.columns if col_name != 'Random_ID']\n",
    "    # last_reg.drop(['RegistrationTime', 'OutCome', 'DonationLocation', 'DaysSinceLastDonation', 'LastDonationType_WholeBlood'], axis=1, inplace=True)\n",
    "    last_reg.drop(['RegistrationTime', 'OutCome', 'DonationLocation', 'DaysSinceLastDonation', 'LastDonationType'], axis=1, inplace=True)\n",
    "\n",
    "    # Calculate frequency: number of registrations for donation in the history period\n",
    "    frequency = cutoff_history.groupby(by='Random_ID', as_index=False).agg({'RegistrationTime': 'count'}).rename(columns={'RegistrationTime': 'PastRegistrations'})    \n",
    "\n",
    "    # Calculate frequency by DonationType\n",
    "    frequency_type = cutoff_history.groupby(by=['Random_ID', 'DonationType'], as_index=False) \\\n",
    "                                   .agg({'RegistrationTime': 'count'}).rename(columns={'RegistrationTime': 'TotalRegistrations'}) \\\n",
    "                                   .pivot(index='Random_ID', columns='DonationType', values='TotalRegistrations') \\\n",
    "                                   .reset_index().rename_axis(None, axis=1)  # Make Random_ID a column; remove index name\n",
    "    frequency_type.columns = ['Random_ID'] + ['Past' + col_name.replace(' ', '') + 'Registrations' for col_name in frequency_type.columns if col_name != 'Random_ID']\n",
    "\n",
    "    # Calculate frequency just for platelet products\n",
    "    frequency_platelets = cutoff_history[cutoff_history['DonationType'].isin(['RBC with Platelets', 'Platelet Apheresis',\n",
    "                                                                              'RBC with Platelets and Plasma', 'Platelets and Concurrent Plasma'])] \\\n",
    "                                                                       .groupby(by='Random_ID', as_index=False) \\\n",
    "                                                                       .agg({'RegistrationTime': 'count'}).rename(columns={'RegistrationTime': 'PastPlateletRegistrations'}) \n",
    "\n",
    "    # Filter data down to target period\n",
    "    cutoff_target = cleaned_data[(cleaned_data['RegistrationTime'] >= target_start_date) & (cleaned_data['RegistrationTime'] <= target_end_date)]\n",
    "\n",
    "    # Calculate base measure for target: how many total registrations each donor had in the target period\n",
    "    response = cutoff_target.groupby(by='Random_ID', as_index=False).agg({'RegistrationTime': 'count'}).rename(columns={'RegistrationTime': 'TargetRegistrations'})\n",
    "    \n",
    "    # Calculate sub-targets: how many registrations of each DonationType each donor had in the target period\n",
    "    response_type = cutoff_target.groupby(by=['Random_ID', 'DonationType'], as_index=False) \\\n",
    "                                 .agg({'RegistrationTime': 'count'}).rename(columns={'RegistrationTime': 'TotalRegistrations'}) \\\n",
    "                                 .pivot(index='Random_ID', columns='DonationType', values='TotalRegistrations') \\\n",
    "                                 .reset_index().rename_axis(None, axis=1)\n",
    "    response_type.columns = ['Random_ID'] + ['Target' + col_name.replace(' ', '') + 'Registrations' for col_name in response_type.columns if col_name != 'Random_ID']    \n",
    "\n",
    "    # Calculate target for platelet donations (combined):\n",
    "    response_platelets = cutoff_target[cutoff_target['DonationType'].isin(['RBC with Platelets', 'Platelet Apheresis',\n",
    "                                                                           'RBC with Platelets and Plasma', 'Platelets and Concurrent Plasma'])] \\\n",
    "                                                                    .groupby(by='Random_ID', as_index=False) \\\n",
    "                                                                    .agg({'RegistrationTime': 'count'}).rename(columns={'RegistrationTime': 'TargetPlateletRegistrations'})     \n",
    "\n",
    "    # Calculate registrations per location type\n",
    "    location_counts = cutoff_history.groupby(by=['Random_ID', 'DonationLocation'], as_index=False) \\\n",
    "                                    .agg({'RegistrationTime': 'count'}).rename(columns={'RegistrationTime': 'TotalRegistrations'})\n",
    "    \n",
    "    # Pivot to add as features\n",
    "    frequency_location = location_counts.pivot(index='Random_ID', columns='DonationLocation', values='TotalRegistrations').reset_index().rename_axis(None, axis=1)\n",
    "    frequency_location.columns = ['Random_ID'] + ['Past' + col_name.replace(' ', '') + 'Registrations' for col_name in frequency_location.columns if col_name != 'Random_ID']\n",
    "    frequency_location.fillna(0, inplace=True)\n",
    "    frequency_location['CenterRegistrationProportion'] = frequency_location['PastCenterRegistrations'] / (frequency_location['PastMobileRegistrations'] + frequency_location['PastCenterRegistrations'])\n",
    "    \n",
    "\n",
    "    # Calculate modal location per Random_ID\n",
    "    modal_location = location_counts.sort_values('TotalRegistrations', ascending=False).groupby(by='Random_ID').head(1).rename(columns={'DonationLocation': 'ModalDonationLocation'})\n",
    "    # Represent modal location as dummy variables - dropping the dummy for mobile locations to prevent multicollinearity\n",
    "    modal_dummies = pd.get_dummies(modal_location).drop(['TotalRegistrations', 'ModalDonationLocation_Mobile'], axis=1)\n",
    "\n",
    "    # Combine datasets to create a subset for the current cutoff date\n",
    "    # cutoff_subset = pd.merge(recency, frequency, how='left') \\\n",
    "    #                   .merge(recency_type, how='left') \\\n",
    "    #                   .merge(last_reg, how='left') \\\n",
    "    #                   .merge(frequency_type, how='left') \\\n",
    "    #                   .merge(frequency_location, how='left') \\\n",
    "    #                   .merge(frequency_platelets, how='left') \\\n",
    "    #                   .merge(modal_dummies, how='left') \\\n",
    "    #                   .merge(response, how='left') \\\n",
    "    #                   .merge(response_type, how='left') \\\n",
    "    #                   .merge(response_platelets, how='left')\n",
    "    cutoff_subset = pd.merge(recency, frequency, how='left') \\\n",
    "                      .merge(last_reg, how='left') \\\n",
    "                      .merge(frequency_location, how='left') \\\n",
    "                      .merge(frequency_platelets, how='left') \\\n",
    "                      .merge(modal_dummies, how='left') \\\n",
    "                      .merge(response, how='left')\n",
    "\n",
    "    # Add more features based on metadata or interactions    \n",
    "    nonzero_time_mask = (cutoff_subset['DaysSinceFirstRegistration'] != 0)\n",
    "    cutoff_subset['DonationsPerDay'] = 1\n",
    "    nonzero_time_subset = cutoff_subset[nonzero_time_mask]\n",
    "    cutoff_subset.loc[nonzero_time_mask, 'DonationsPerDay'] = nonzero_time_subset['PastRegistrations'] / nonzero_time_subset['DaysSinceFirstRegistration']\n",
    "    cutoff_subset['PlateletRegistrationProportion'] = cutoff_subset['PastPlateletRegistrations'] / cutoff_subset['PastRegistrations']\n",
    "    cutoff_subset['CutoffDate'] = cutoff\n",
    "    cutoff_subset['RegisteredInTargetPeriod'] = cutoff_subset['TargetRegistrations'].apply(lambda x: 0 if pd.isna(x) or x == 0 else 1)\n",
    "    # cutoff_subset['RegisteredForPlateletsInTargetPeriod'] = cutoff_subset['TargetPlateletRegistrations'].apply(lambda x: 0 if pd.isna(x) or x == 0 else 1)\n",
    "    # cutoff_subset['TargetPeriodEndDate'] = target_end_date  # Target period start date is implicitly midnight of the day after the cutoff date    \n",
    "\n",
    "    # Replace NaNs (the result of outer joins) with 0\n",
    "    cutoff_subset.fillna(0, inplace=True)\n",
    "\n",
    "    # Drop ineligible donors\n",
    "#     cutoff_subset = cutoff_subset[(cutoff_subset['PercentOfTargetPeriodEligible'] > 0) & (cutoff_subset['DaysSinceLastRegistration'] <= 12*target_window_size)]\n",
    "    cutoff_subset = cutoff_subset[(cutoff_subset['PercentOfTargetPeriodEligible'] > 0)]\n",
    "\n",
    "    # Add the current subset to the list to combine later\n",
    "    cutoff_subsets.append(cutoff_subset)\n",
    "\n",
    "    # Append to CSV\n",
    "    if iteration > 0:\n",
    "        include_header = False\n",
    "    \n",
    "    cutoff_subset.to_csv(f'../../data/processed/{filename}', index=False, header=include_header, mode='a')\n",
    "    iteration += 1\n",
    "\n",
    "# Combine all cutoff subsets together for processed data\n",
    "data = pd.concat(cutoff_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Random_ID': 'int64', 'DaysSinceLastRegistration': 'int64', 'DaysSinceFirstRegistration': 'int64', 'PastRegistrations': 'int64', 'DaysEligible': 'float64', 'PercentOfTargetPeriodEligible': 'float64', 'LastDonationLocation_Center': 'float64', 'LastDonationType_Platelets': 'float64', 'PastCenterRegistrations': 'float64', 'PastMobileRegistrations': 'float64', 'CenterRegistrationProportion': 'float64', 'PastPlateletRegistrations': 'float64', 'ModalDonationLocation_Center': 'uint8', 'TargetRegistrations': 'float64', 'DonationsPerDay': 'float64', 'PlateletRegistrationProportion': 'float64', 'RegisteredInTargetPeriod': 'int64'}\n",
      "{'CutoffDate': 'datetime64[ns]'}\n"
     ]
    }
   ],
   "source": [
    "# Save data types as a dict for reading\n",
    "#dtypes_dict = data.dtypes.to_frame('dtypes').reset_index().set_index('index')['dtypes'].astype(str).to_dict()\n",
    "data_dtypes = data.dtypes.to_frame('dtypes').reset_index().set_index('index')['dtypes'].astype(str)\n",
    "non_date_dtypes = data_dtypes[data_dtypes != 'datetime64[ns]'].to_dict()\n",
    "date_dtypes = data_dtypes[data_dtypes == 'datetime64[ns]'].to_dict()\n",
    "\n",
    "with open('../../data/processed/dtypes.json', 'w') as out_file:\n",
    "    json.dump(non_date_dtypes, out_file)\n",
    "\n",
    "with open('../../data/processed/date_types.json', 'w') as out_file:\n",
    "    json.dump(date_dtypes, out_file)\n",
    "\n",
    "print(non_date_dtypes)\n",
    "print(date_dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
