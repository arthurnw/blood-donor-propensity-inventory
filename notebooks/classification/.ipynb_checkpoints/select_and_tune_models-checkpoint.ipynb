{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "np.random.seed(503)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring = 'precision'  # Precision: TP / (TP + FN), or % of predicted positives that are actually positive\n",
    "# scoring = 'balanced_accuracy'\n",
    "# scoring = 'roc_auc'\n",
    "scoring = 'average_precision'  # Average of precision at all possible thresholds. 1) We have many donors, so we would like a model whose positive predictions are mostly correct (so we don't waste scarce resources), but we don't need to return ALL condition positives. Precision is a more suitable metric than recall here. 2) We don't necessarily care about correctly classifying any individual donor - we care more about the relative likelihood of a donor compared to other donors, so we don't want to pick a single decision threshold, but summarize how well the classifier orders any given donor compared to others.\n",
    "\n",
    "# Decide whether we're loading a subset or the full set\n",
    "# dataset_size = 'partial'\n",
    "dataset_size = 'full'\n",
    "\n",
    "if dataset_size == 'full':\n",
    "    file_names = {\n",
    "        'X': 'X_train_full.csv',\n",
    "        'y': 'y_train_full.csv'\n",
    "    }\n",
    "elif dataset_size == 'partial':\n",
    "    file_names = {\n",
    "        'X': 'X_train.csv',\n",
    "        'y': 'y_train.csv'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rthrw\\miniconda3\\envs\\oneblood-inventory\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "with open('../../data/processed/dtypes.json') as in_file:\n",
    "    non_date_dtypes = json.load(in_file)\n",
    "\n",
    "with open('../../data/processed/date_types.json') as in_file:\n",
    "    date_dtypes = json.load(in_file)\n",
    "\n",
    "date_cols = list(date_dtypes)\n",
    "\n",
    "# Read data, specifically parsing date columns as dates and only picking the features + target\n",
    "X_train = pd.read_csv('../../data/processed/{0}'.format(file_names['X']), dtype=non_date_dtypes, index_col=0)\n",
    "y_train = pd.read_csv('../../data/processed/{0}'.format(file_names['y']), index_col=0).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DaysSinceLastRegistration</th>\n",
       "      <th>DaysSinceFirstRegistration</th>\n",
       "      <th>PastRegistrations</th>\n",
       "      <th>LastDonationLocation_Center</th>\n",
       "      <th>LastDonationType_Platelets</th>\n",
       "      <th>CenterRegistrationProportion</th>\n",
       "      <th>DonationsPerDay</th>\n",
       "      <th>PlateletRegistrationProportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22582640</th>\n",
       "      <td>209</td>\n",
       "      <td>740</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13737826</th>\n",
       "      <td>592</td>\n",
       "      <td>592</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10728157</th>\n",
       "      <td>257</td>\n",
       "      <td>313</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13802601</th>\n",
       "      <td>153</td>\n",
       "      <td>515</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18546659</th>\n",
       "      <td>401</td>\n",
       "      <td>401</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DaysSinceLastRegistration  DaysSinceFirstRegistration  \\\n",
       "22582640                        209                         740   \n",
       "13737826                        592                         592   \n",
       "10728157                        257                         313   \n",
       "13802601                        153                         515   \n",
       "18546659                        401                         401   \n",
       "\n",
       "          PastRegistrations  LastDonationLocation_Center  \\\n",
       "22582640                  2                          0.0   \n",
       "13737826                  1                          0.0   \n",
       "10728157                  2                          0.0   \n",
       "13802601                  4                          0.0   \n",
       "18546659                  1                          0.0   \n",
       "\n",
       "          LastDonationType_Platelets  CenterRegistrationProportion  \\\n",
       "22582640                         0.0                           0.0   \n",
       "13737826                         0.0                           0.0   \n",
       "10728157                         0.0                           0.0   \n",
       "13802601                         0.0                           0.0   \n",
       "18546659                         0.0                           0.0   \n",
       "\n",
       "          DonationsPerDay  PlateletRegistrationProportion  \n",
       "22582640         0.002703                             0.0  \n",
       "13737826         0.001689                             0.0  \n",
       "10728157         0.006390                             0.0  \n",
       "13802601         0.007767                             0.0  \n",
       "18546659         0.002494                             0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22582640    0\n",
       "13737826    0\n",
       "10728157    0\n",
       "13802601    0\n",
       "18546659    0\n",
       "Name: RegisteredInTargetPeriod, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code from: http://www.davidsbatista.net/blog/2018/02/23/model_optimization/\n",
    "\n",
    "class EstimatorSelectionHelper:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=3, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            print(k)\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'XGBClassifier': XGBClassifier(),    \n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "    'GaussianNB': GaussianNB(),\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'LogisticRegression': { 'penalty': ['none', 'l2'] },  # Default params: dual=False, tol=1e-4, C=1.0, fit_intercept=True, intercept_scaling=1...\n",
    "    'RandomForestClassifier': { 'n_estimators': [100], 'max_depth': [5] },  # Default params: criterion='gini', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0...\n",
    "    'AdaBoostClassifier': { 'n_estimators': [100], 'learning_rate': [1] },  # Default params: base_estimator=None (DecisionTreeClassifier w/ max_depth=1), aglorithm='SAMME.R\n",
    "    'XGBClassifier': { 'learning_rate': [0.5], 'n_estimators': [100], 'max_depth': [5], 'tree_method': ['hist'] },\n",
    "    'DecisionTreeClassifier': {},  # Default params: criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1...\n",
    "    'GaussianNB': {},  # sklearn implementation automatically calculates priors\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for LogisticRegression.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of   6 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RandomForestClassifier.\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed: 36.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed: 37.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for XGBClassifier.\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for DecisionTreeClassifier.\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for GaussianNB.\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:   32.6s finished\n"
     ]
    }
   ],
   "source": [
    "# Run grid search CV across all estimators\n",
    "helper = EstimatorSelectionHelper(models, params)\n",
    "helper.fit(X_train, y_train, scoring=scoring, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "RandomForestClassifier\n",
      "AdaBoostClassifier\n",
      "XGBClassifier\n",
      "DecisionTreeClassifier\n",
      "GaussianNB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>penalty</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>tree_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.305453</td>\n",
       "      <td>0.305535</td>\n",
       "      <td>0.305646</td>\n",
       "      <td>8.14249e-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>hist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.285788</td>\n",
       "      <td>0.285867</td>\n",
       "      <td>0.285937</td>\n",
       "      <td>6.11006e-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.283268</td>\n",
       "      <td>0.283771</td>\n",
       "      <td>0.284144</td>\n",
       "      <td>0.000369363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.252981</td>\n",
       "      <td>0.253321</td>\n",
       "      <td>0.253598</td>\n",
       "      <td>0.00025551</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.252981</td>\n",
       "      <td>0.253311</td>\n",
       "      <td>0.253569</td>\n",
       "      <td>0.000245361</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.181932</td>\n",
       "      <td>0.182073</td>\n",
       "      <td>0.182184</td>\n",
       "      <td>0.000104941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.142914</td>\n",
       "      <td>0.143243</td>\n",
       "      <td>0.143441</td>\n",
       "      <td>0.000234323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                estimator min_score mean_score max_score    std_score penalty  \\\n",
       "4           XGBClassifier  0.305453   0.305535  0.305646  8.14249e-05     NaN   \n",
       "3      AdaBoostClassifier  0.285788   0.285867  0.285937  6.11006e-05     NaN   \n",
       "2  RandomForestClassifier  0.283268   0.283771  0.284144  0.000369363     NaN   \n",
       "1      LogisticRegression  0.252981   0.253321  0.253598   0.00025551      l2   \n",
       "0      LogisticRegression  0.252981   0.253311  0.253569  0.000245361    none   \n",
       "6              GaussianNB  0.181932   0.182073  0.182184  0.000104941     NaN   \n",
       "5  DecisionTreeClassifier  0.142914   0.143243  0.143441  0.000234323     NaN   \n",
       "\n",
       "  max_depth n_estimators learning_rate tree_method  \n",
       "4         5          100           0.5        hist  \n",
       "3       NaN          100             1         NaN  \n",
       "2         5          100           NaN         NaN  \n",
       "1       NaN          NaN           NaN         NaN  \n",
       "0       NaN          NaN           NaN         NaN  \n",
       "6       NaN          NaN           NaN         NaN  \n",
       "5       NaN          NaN           NaN         NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper.score_summary(sort_by='mean_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 1\n",
    "* Partial dataset: `GradientBoostingClassifier` with `n_estimators` = 128, `learning_rate` = 0.5 had the best performance with a mean average precision of **0.674885**.\n",
    "* Full dataset: `RandomForestClassifier` with `n_estimators` = 64 had the best performance with a mean average precision of **0.799422**.\n",
    "\n",
    "## Run 2\n",
    "* Full dataset: `GradientBoostingClassifier` with `n_estimators` = 128, `learning_rate` = 0.5, `mean_score` = 0.703001\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
